{
  "hash": "f413df51b544b9f4f3066eb11b729c4e",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Application de la VaR\nsidebar: auto\ndate: \"2024-07-28\"\nauthor:\n  - Cheryl Kouadio\n---\n\n\n# Introduction  \n\nNous allons ici nous intéresser aux applications de la Value at Risk (VaR) en finance. La VaR est une mesure de risque qui permet d'estimer les pertes maximales potentielles d'un portefeuille  d'actifs financiers sur un horizon de temps donné, à un certain niveau de confiance. Elle est largement utilisée par les institutions financières pour évaluer et gérer les risques de marché, de crédit et de liquidité (cf. [Value at-Risk](3A/3A/value-at-risk/var_def.qmd#sec-var-def)).\n\nNous verrons ainsi les applications des VaR analytique, historique et Monte Carlo.\n\n# Import des données\n\nNous utilisons les données du CAC 40 du 01/03/1990 au 10/05/2024. Le CAC 40 (Cotation Assistée en Continu) est l'indice boursier le plus important de la Bourse de Paris. Son nom signifie que c'est un indice composé des 40 sociétés françaises les plus significatives et les plus liquides cotées sur Euronext Paris, qui est l'une des principales places boursières en Europe.\n\n::: {#e45ff664 .cell execution_count=2}\n``` {.python .cell-code}\n# Librairie où importer les données\nimport yfinance as yf\n_ = yf.Ticker(\"^FCHI\")\nts_data = _.history(\"max\")\nts_data.index = ts_data.index.strftime('%Y-%m-%d')\nts_data.columns\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n/Users/cherylkouadio/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning:\n\nurllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nIndex(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')\n```\n:::\n:::\n\n\nLa prix de la clôture, c'est à dire, le prix final de l'indice à la fin de la session de trading sur Euronext Paris, est la bourse où l'indice est coté. Celà reflète l'impact des nouvelles économiques, des performances des entreprises comprises dans l'indice, et des mouvements généraux du marché.\n\nNous l'utiliserons pour calculer le rendement (arithmétique) pour avoir le pourcentage de changement de prix pour l'indice CAC40 qui définit notre distribution de probabilité pour les gains ou les pertes quotidiens.\n\nLe rendement entre $t$ et $t-1$ se calcule comme suit :\n\n$$\nR_{t} = \\frac{P_{t}-P_{t-1}}{P_{t-1}}\n$$\n\noù $P_{t}$ est le prix de clôture à la date $t$.\n\n::: {#d7d9623e .cell execution_count=3}\n``` {.python .cell-code}\nimport warnings\nwarnings.filterwarnings('ignore')\nts_data = ts_data[[ 'Close']]\nimport pandas as pd\nimport numpy as np\n\n\nts_data['Return'] = ts_data[\"Close\"].pct_change()\nts_data = ts_data.dropna(subset=['Return'])\nprint(ts_data.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Close    Return\nDate                        \n1990-03-02  1860.0  0.015284\n1990-03-05  1874.0  0.007527\n1990-03-06  1872.0 -0.001067\n1990-03-07  1880.0  0.004274\n1990-03-08  1917.0  0.019681\n```\n:::\n:::\n\n\n# Test de stationarité du log-rendement\n\nPour utiliser le rendement comme variable profit et perte (PnL : Profit and Loss) pour impléter la VaR, nous devons tester sa stationarité. En effet, la stationarité est une propriété importante des séries temporelles financières. Une série temporelle est dite stationnaire si ses propriétés statistiques telles que la moyenne, la variance et la covariance restent constantes au fil du temps.\n\n::: {#d779bcd6 .cell execution_count=4}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6, 4))\n\nfig, ax = plt.subplots(1)\n\nax.set_xlabel('Date')\nax.set_ylabel('Historical Returns')\nax.plot(ts_data.index, ts_data['Return'], color='grey')\nax.tick_params(axis='y')\n\nplt.title('Historical Returns of CAC40')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n```\n<Figure size 576x384 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-4-output-2.png){width=623 height=449}\n:::\n:::\n\n\nIl semblerait que la série des rendements est stationnaire. Nous allons tout de même en observant l'ACF et le PACF mais aussi effectuer un test de stationarité pour confirmer cette hypothèse.\n\n::: {#6c1d28fa .cell execution_count=5}\n``` {.python .cell-code}\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfig, ax = plt.subplots(1,2, figsize=(8, 4))\nplot_acf(ts_data['Return'].dropna(), ax=ax[0],title='ACF')\nplot_pacf(ts_data['Return'].dropna(), ax=ax[1],title='PACF')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-5-output-1.png){width=665 height=357}\n:::\n:::\n\n\nL'autocorrélation(ACF) et l'autocorrélation partielle(PACF) décroissent de manière exponentielle, ce qui indique que la série est stationnaire. \n\nPour plus de certitude, nous allons effectuer un test de Dickey-Fuller augmenté (ADF) pour tester la stationnaire dans la série :\n\n$$ \nH_0=\\rho = 1, \\alpha=0\n$$ \n\nDans le cas d'une série AR(1)($X_t = \\alpha + \\rho X_{t-1} + \\xi_t$) avec intercept, la série est non stationnaire si $\\rho = 1$ et stationnaire si $\\rho < 1.  Dans le cas contraire, il faudrait considérer la série de différences pour la rendre stationnaire.\n\n::: {#e15a1f47 .cell execution_count=6}\n``` {.python .cell-code}\nfrom statsmodels.tsa.stattools import adfuller\nadf_result = adfuller(ts_data['Return'].dropna(), regression='c')\nprint(f\"ADF Statistic: {round(adf_result[0],2)} and p-value: {adf_result[1]}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nADF Statistic: -41.48 and p-value: 0.0\n```\n:::\n:::\n\n\nLa p-value du test de dickey fuller est environ égale à 0, ce qui signifie que nous rejetons l'hypothèse nulle selon laquelle la série n'est pas stationnaire. Ainsi la série des log-rendements est stationnaire. Nous pouvons donc utiliser les rendements logarithmiques pour calculer la VaR à horizon 1 jour.\n\n# Modélisation de la VaR\n\nPour modéliser la VaR, nous considérons un échantillon d'apprentissage avec 75% (6513) des données et 25% (2172) pour l'échantillon de test.\n\n::: {#3c567751 .cell execution_count=7}\n``` {.python .cell-code}\ntrain_size = int(len(ts_data)*0.75)\ntest_size = len(ts_data)-train_size\n\ntrain_close = ts_data.iloc[0:train_size,:].dropna()\ntest_close = ts_data.iloc[train_size:len(ts_data),:]\nprint(\"Taille de l'ensemble d'apprentissage :\", len(train_close))\nprint(\"Taille de l'ensemble de test :\", len(test_close))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTaille de l'ensemble d'apprentissage : 6665\nTaille de l'ensemble de test : 2222\n```\n:::\n:::\n\n\n## VaR analytique\n\nPour rappel, la VaR analytique ou gaussienne est basée sur la distribution gaussienne des rendements. Nous allons utiliser la distribution normale pour calculer la VaR à horizon 1 jour. La VaR à horizon 1 jour est définie comme suit :\n\n$$\nVaR = -\\mu_{PnL} + \\Phi^{-1}(\\alpha) \\times \\sigma_{PnL}\n$$\noù $\\Phi^{-1}(\\alpha)$ est le quantile de la distribution normale du PnL (Profit and Loss) à $\\alpha$.\n\nPour ce faire, nous allons tester que les rendements suivent une loi normale. Nous utiliserons le test de Shapiro (`shapiro` dans la librairie `scipy.stats`) dont l'hypothèse nulle est que la population étudiée suit une distribution normale.\n\n::: {#735ad351 .cell execution_count=8}\n``` {.python .cell-code}\nfrom scipy import stats\nstats.shapiro(train_close[\"Return\"]).pvalue\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\nnp.float64(5.073604966554165e-41)\n```\n:::\n:::\n\n\nNous obtenons une pvaleur quasiment nulle donc nous rejettons l'hypothèse de la distribution normale de nos rendements.\nCelà est plus visible avec le QQ-plot ci dessous qui montre clairement que les queues de distribution du rendement ne suit pas une loi normale.\n\n::: {#57073eee .cell execution_count=9}\n``` {.python .cell-code}\n## Analyse graphique avec le QQ-plot\nplt.figure(figsize=(8, 6))\nprobplot = stats.probplot(train_close[\"Return\"], \n                        sparams = (np.mean(train_close[\"Return\"]), np.std(train_close[\"Return\"])), \n                        dist='norm', plot=plt)\nplt.plot(probplot[0][0], probplot[0][0], color='red', linestyle='dashed', linewidth=2, label='Première bissectrice')\nplt.title('QQ-plot')\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\nText(0.5, 1.0, 'QQ-plot')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-9-output-2.png){width=691 height=523}\n:::\n:::\n\n\n::: {#2375a9d9 .cell execution_count=10}\n``` {.python .cell-code}\nfrom scipy import stats\ndef gaussian_var(PnL, seuil):\n    mean_PnL = np.mean(PnL)\n    sd_PnL = np.std(PnL)\n    VaR = - mean_PnL + sd_PnL * stats.norm.ppf(seuil)\n    return VaR\n\nseuil = 0.99\nVaR_gaussienne = gaussian_var(train_close[\"Return\"], seuil)\n\nprint(f\"La VaR à horizon 1 jour est de {round(VaR_gaussienne, 4)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLa VaR à horizon 1 jour est de 0.0326\n```\n:::\n:::\n\n\nLa VaR à horizon 1 jour est de 0.0324, ce qui signifie que la perte maximale en terme de rendements du portefeuille est de 3.24% en un jour. \n\nSur 10 jours, la VaR est de $VaR_{1j} \\times \\sqrt{10}=$ 10.24%.\nPour le visualiser sur la distribution des rendements, nous avons le graphique ci-dessous :\n\n::: {#812160ae .cell execution_count=11}\n``` {.python .cell-code}\n# Plot histogram of returns\nplt.hist(train_close[\"Return\"], bins=50, density=True, alpha=0.7,color=\"grey\")\n\n# Plot VaR line\nplt.axvline(x=-VaR_gaussienne, color=\"orange\", linestyle=\"--\", linewidth=1)\nplt.axvline(x=0, color=\"grey\",  linewidth=0.5)\n\n# Add text for Loss and Gain\nplt.text(-0.01, plt.ylim()[1] * 0.9, 'Pertes', horizontalalignment='right', color='red')\nplt.text(0.01, plt.ylim()[1] * 0.9, 'Gains', horizontalalignment='left', color='green')\n\n\n# Add labels and title\nplt.xlabel(\"Returns\")\nplt.ylabel(\"Frequency\")\nplt.title(f\"Gaussian VaR at {seuil * 100}%, Var: {VaR_gaussienne:.4f}\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-11-output-1.png){width=585 height=449}\n:::\n:::\n\n\n### Backtesting\n\nPour backtester la VaR, nous allons comparer dans l'échantillon test les rendements avec la VaR à horizon 1 jour. Si le rendement est inférieur à l'opposé de la VaR gaussienne, alors la VaR est violée et celà correspond à une exception.\n\nCi dessous, le graphique qui permet de visualiser le nombre d'exceptions que nous comptabilisons sur nos données test.\n\n::: {#c8192721 .cell execution_count=12}\n``` {.python .cell-code}\nplt.plot(ts_data.index[0:train_size], train_close['Return'], label=\"historical train returns\", color = 'gray')\nplt.plot(ts_data.index[train_size:], test_close['Return'], label=\"historical test returns\", color = 'blue')\nplt.plot(ts_data.index[train_size:], [-VaR_gaussienne for i in range(test_size)], label=\"gaussian VaR\", color = 'red')\nlist_exceptions_gaus = [i for i in range(len(test_close['Return'])) if test_close['Return'][i]<-VaR_gaussienne]\nplt.scatter(test_close.index[list_exceptions_gaus], test_close['Return'][list_exceptions_gaus], color='red', label='Exceptions')\nplt.title('CAC40')\nplt.ylabel('Values')\nplt.plot()\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-12-output-1.png){width=623 height=431}\n:::\n:::\n\n\nNous pouvons compter le nombre d'exceptions pour la VaR à horizon 1 jour qui est égale à 30 et en déduisons que le taux d'exception est 1.38%.\n\n::: {#741492cd .cell execution_count=13}\n``` {.python .cell-code}\nround((len(list_exceptions_gaus)/test_size)*100,2) \n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n1.13\n```\n:::\n:::\n\n\nPour tester la pertinence de la VaR calculée, il faudrait idéalement que le taux d'exception soit inférieur à 1%. Pour ce faire, nous pouvons effectuer un test de proportion. Nous utiliserons la fonction `stats.binomtest` pour effectuer ce test.\n\n::: {#f64c8b39 .cell execution_count=14}\n``` {.python .cell-code}\ndef ptest(p0,n,k) :\n  variance=p0*(1-p0)/n\n  p=(k/n)\n  t=(p-p0)/np.sqrt(variance)\n\n  pvaleur=1-stats.norm.cdf(t)\n  return pvaleur\n\nptest(0.01,test_size,len(list_exceptions_gaus))\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nnp.float64(0.27668172410611824)\n```\n:::\n:::\n\n\nLa pvaleur de ce test est 3.70%, celà est inférieur à 5% donc nous rejetons l'hypothèse nulle selon laquelle le taux d'exception est égale à 0.01 au risque 5% de se tromper. Celà nous indique que la VaR gaussienne n'est pas performante. Ceci n'est pas surprenant étant donné que nous faisons une hypothèse sur la distribution des rendements qui n'est pas vérifiée. \n\n## VaR historique\n\nLa VaR historique est basée sur les rendements historiques. Elle est définie comme l'opposé du quantile de niveau $1-\\alpha$ des rendements historiques. \n\nConsidérons les mouvements de prix quotidiens pour l'indice CAC40 au cours des 6513 jours de trading. Nous avons donc 6513 scénarios ou cas qui serviront de guide pour les performances futures de l'indice, c'est-à-dire que les 6513 derniers jours seront représentatifs de ce qui se passera demain.\n\nAinsi donc la VaR historique pour un horizon de 1jour à 99% correspond au 1er percentile de la distribution de probabilité des rendements quotidiens (le top 1% des pires rendements).\n\n::: {#a402ef91 .cell execution_count=15}\n``` {.python .cell-code}\ndef historical_var(PnL, seuil):\n    return -np.percentile(PnL, (1 - seuil) * 100)\n\nVaR_historique = historical_var(train_close[\"Return\"],seuil)\nprint(f\"La VaR historique à horizon 1 jour est de {round(VaR_historique, 4)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLa VaR historique à horizon 1 jour est de 0.0396\n```\n:::\n:::\n\n\nNous en déduisons que la perte maximale en terme de rendements du portefeuille est de 3.96% en un jour (soit 12.52% en 10jours)\n\n::: {#5d3429cd .cell execution_count=16}\n``` {.python .cell-code}\n# Plot histogram of returns\nplt.hist(train_close[\"Return\"], bins=50, density=True, alpha=0.7,color=\"grey\")\n\n# Plot VaR line\nplt.axvline(x=-VaR_historique, color=\"orange\", linestyle=\"--\", linewidth=1)\nplt.axvline(x=0, color=\"grey\",  linewidth=1)\n# Add text for Loss and Gain\nplt.text(- 0.01, plt.ylim()[1] * 0.9, 'Pertes', horizontalalignment='right', color='red')\nplt.text(0.01, plt.ylim()[1] * 0.9, 'Gains', horizontalalignment='left', color='green')\n\n\n# Add labels and title\nplt.xlabel(\"Returns\")\nplt.ylabel(\"Frequency\")\nplt.title(f\"Historical VaR at {seuil * 100}% Var: {VaR_historique:.4f}\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-16-output-1.png){width=585 height=449}\n:::\n:::\n\n\n### Backtesting\n\nEn ce qui concerne le backtesting, nous pouvons voir que la VaR historique est beaucoup moins violée dans l'échantillon test que la VaR gaussienne. Le taux d'exception est de 0.64%.\n\n::: {#8cc1cda3 .cell execution_count=17}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nplt.plot(ts_data.index[0:train_size], train_close['Return'], label=\"historical train returns\", color = 'gray')\nplt.plot(ts_data.index[train_size:], test_close['Return'], label=\"historical test returns\", color = 'blue')\nplt.plot(ts_data.index[train_size:], [-VaR_historique for i in range(test_size)], label=\"historical VaR\", color = 'red')\nlist_exceptions_hist = [i for i in range(len(test_close['Return'])) if test_close['Return'][i]<-VaR_historique]\nplt.scatter(test_close.index[list_exceptions_hist], test_close['Return'][list_exceptions_hist], color='red', label='Exceptions')\nplt.title('CAC40')\nplt.ylabel('Values')\nplt.plot()\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-17-output-1.png){width=623 height=431}\n:::\n:::\n\n\nNous pouvons compter le nombre d'exceptions pour la VaR à horizon 1 jour qui est égale à 14 et en déduisons que le taux d'exception est 0.64%. Ce taux d'exception est statistiquement supérieur à 1% (car la pvaleur est d'environ 0.95). Ainsi, la VaR historique est performante pour la période considérée.\n\n::: {#6e786dd3 .cell execution_count=18}\n``` {.python .cell-code}\nround((len(list_exceptions_hist)/test_size)*100,2) \nptest(0.01,test_size,len(list_exceptions_hist))\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\nnp.float64(0.9853349189614367)\n```\n:::\n:::\n\n\n## VaR Monte Carlo\n\nLa VaR Monte Carlo est basée sur la simulation de trajectoires de rendements. Nous allons simuler jusqu'à 10000 scénarios de rendements et calculer la VaR à horizon 1 jour en posant une hypothèse de normalité sur la distribution des rendements afin de voir quand est ce que la VaR se stabilise.\n\n::: {#7644a60b .cell execution_count=19}\n``` {.python .cell-code}\nVaR_results = []\n\nnum_simulations_list = range(10, 10000 + 1, 1)\nmean=train_close[\"Return\"].mean()\nstd = train_close[\"Return\"].std()\n\nfor num_simulations in num_simulations_list:\n  # Generate random scenarios of future returns\n  simulated_returns = np.random.normal(mean, std, size= num_simulations)\n\n  # Calculate portfolio values for each scenario\n  portfolio_values = (train_close[\"Close\"].iloc[-1] * (1 + simulated_returns))\n\n  # Convert portfolio_values into a DataFrame\n  portfolio_values = pd.DataFrame(portfolio_values)\n\n  # Calculate portfolio returns for each scenario\n  portfolio_returns = portfolio_values.pct_change()\n  portfolio_returns=portfolio_returns.dropna()\n  portfolio_returns=portfolio_returns.mean(axis=1)\n\n\n  # Calculate VaR\n  if portfolio_returns.iloc[-1] != 0:\n      VaR_monte_carlo =  historical_var(portfolio_returns,seuil)\n  else:\n      VaR_monte_carlo = 0\n  \n  VaR_results.append(VaR_monte_carlo)\n```\n:::\n\n\n::: {#ce013915 .cell execution_count=20}\n``` {.python .cell-code}\n# Plotting the results\nplt.figure(figsize=(10, 6))\nplt.xticks(np.arange(0,10000 + 1, 1000))\nplt.plot(num_simulations_list, VaR_results, linestyle='-')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Value at Risk (VaR)')\nplt.title('VaR vs Number of Simulations')\nplt.grid(True)\nplt.show()\n# Customize x-axis ticks\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-20-output-1.png){width=829 height=523}\n:::\n:::\n\n\nVisuellement, la VaR se stabilise à partir de 3000 scénarios. Nous utiliserons donc 3000 simulations de rendements. Nous en déduisons que la perte maximale en terme de rendements du portefeuille est de 4.31% en un jour (soit 13.98% en 10jours)\n\n::: {#08547fc6 .cell execution_count=21}\n``` {.python .cell-code}\nnum_simulations = 3000\n\n# Generate random scenarios of future returns\nsimulated_returns = np.random.normal(mean, std, size= num_simulations)\n\n# Calculate portfolio values for each scenario\nportfolio_values = (train_close[\"Close\"].iloc[-1] * (1 + simulated_returns))\n\n# Convert portfolio_values into a DataFrame\nportfolio_values = pd.DataFrame(portfolio_values)\n\n# Calculate portfolio returns for each scenario\nportfolio_returns = portfolio_values.pct_change()\nportfolio_returns=portfolio_returns.dropna()\nportfolio_returns=portfolio_returns.mean(axis=1)\n\n\n# Calculate VaR\nif portfolio_returns.iloc[-1] != 0:\n    VaR_monte_carlo =  historical_var(portfolio_returns,seuil)\nelse:\n    VaR_monte_carlo = 0\n\nVaR_monte_carlo\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\nnp.float64(0.044840183036295236)\n```\n:::\n:::\n\n\n::: {#72749957 .cell execution_count=22}\n``` {.python .cell-code}\n# Plot histogram of returns\nplt.hist(portfolio_returns, bins=50, density=True, alpha=0.7,color=\"grey\")\n\n# Plot VaR line\nplt.axvline(x=-VaR_monte_carlo, color=\"orange\", linestyle=\"--\", linewidth=1)\nplt.axvline(x=0, color=\"grey\",  linewidth=1)\n# Add text for Loss and Gain\nplt.text(- 0.01, plt.ylim()[1] * 0.9, 'Pertes', horizontalalignment='right', color='red')\nplt.text(0.01, plt.ylim()[1] * 0.9, 'Gains', horizontalalignment='left', color='green')\n\n\n# Add labels and title\nplt.xlabel(\"Returns\")\nplt.ylabel(\"Frequency\")\nplt.title(f\"Simulated Returns, Monte carlo VaR at {seuil * 100}% Var: {VaR_monte_carlo:.4f}\")\n\n# Show the plot\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-22-output-1.png){width=611 height=449}\n:::\n:::\n\n\n### Backtesting\n\nEn ce qui concerne le backtesting, nous pouvons voir que la VaR historique est beaucoup moins violée dans l'échantillon test que les deux autres VaRs. En effet, le taux d'exception est de 0.37%.\n\n::: {#dcfbaefc .cell execution_count=23}\n``` {.python .cell-code}\nplt.plot(ts_data.index[0:train_size], train_close['Return'], label=\"historical train log returns\", color = 'gray')\nplt.plot(ts_data.index[train_size:], test_close['Return'], label=\"historical test log returns\", color = 'blue')\nplt.plot(ts_data.index[train_size:], [-VaR_monte_carlo for i in range(test_size)], label=\"Non parametric Bootstrap VaR\", color = 'red')\nlist_exceptions_np_boot = [i for i in range(len(test_close['Return'])) if test_close['Return'][i]<-VaR_monte_carlo]\nplt.scatter(test_close.index[list_exceptions_np_boot], test_close['Return'][list_exceptions_np_boot], color='red', label='Exceptions')\nplt.title('CAC40')\nplt.ylabel('Values')\nplt.plot()\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](var_application_files/figure-html/cell-23-output-1.png){width=623 height=431}\n:::\n:::\n\n\nCe taux est statistiquement inférieur à 1% ce qui temoigne de la performance de la VaR monte carlo.\n\n::: {#6c6117b1 .cell execution_count=24}\n``` {.python .cell-code}\nround((len(list_exceptions_np_boot)/test_size)*100,2) \nptest(0.01,test_size,len(list_exceptions_np_boot))\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\nnp.float64(0.9994129059878106)\n```\n:::\n:::\n\n\n# Comparaison des VaRs\n\nComme on peut le constater, les différentes méthodes d'implémentations de VaR donnent des résultats différents. Toutefois, la VaR la plus performante est la VaR monte carlo en faisant l'hypothèse de distribution normale des rendements.\n\n::: {#98fb14d9 .cell execution_count=25}\n``` {.python .cell-code}\n# Print the VaR values\nprint(f\"Parametric VaR: {VaR_gaussienne:.2%}, Pvalue du backtesting: {ptest(0.01, test_size, len(list_exceptions_gaus)):.4f}\")\nprint(f\"Historical VaR: {VaR_historique:.2%}, Pvalue du backtesting: {ptest(0.01, test_size, len(list_exceptions_hist)):.4f}\")\nprint(f\"Monte Carlo VaR: {VaR_monte_carlo:.2%}, Pvalue du backtesting: {ptest(0.01, test_size, len(list_exceptions_np_boot)):.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParametric VaR: 3.26%, Pvalue du backtesting: 0.2767\nHistorical VaR: 3.96%, Pvalue du backtesting: 0.9853\nMonte Carlo VaR: 4.48%, Pvalue du backtesting: 0.9994\n```\n:::\n:::\n\n\n",
    "supporting": [
      "var_application_files"
    ],
    "filters": [],
    "includes": {}
  }
}