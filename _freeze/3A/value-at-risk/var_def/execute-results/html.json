{
  "hash": "17df085d71230929d93a3be24c53ed91",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"La VaR\"\nauthor: \"Cheryl Kouadio\"\nsidebar: auto\ndate: \"2024-07-27\"\nnumber-sections: true\n---\n\n\n\nLa mesure de risque réglementaire correspond à la valeur en risque ou value at-risk (VaR) qui est le quantile de perte (ou perte maximale subie). Il s'agit dans cette section de développer la notion de VaR pour des portefeuilles linéaires et non linéaires.\n\n# Définition {#sec-var-def}\n\nLa VaR est une mesure de perte (potentielle) qui peut survenir à la suite de variations du marché. Elle permet de réponde à la question : combien l'établissement financier peut-il perdre au maximum avec une probabilité $\\alpha$ sur un horizon de temps fixé à $h$?\n\nPour bien interpréter la Valeur à Risque (VaR), il est donc nécessaire de prendre en compte deux éléments clés, à savoir, la période de détention et le seuil de confiance.\n\nSoit un portefeuille $\\theta$. Notons $P(t,\\theta)$ la valeur de ce portefeuille à la date t. La variation du portefeuille entre $t$ et $t+h$ est appelée le PnL (Profit and Loss) que nous pouvons calculer comme suit :\n\n$$\nPnL = P(t+h, \\theta) - P(t,\\theta)\n$$\n\nLa perte potentielle sera ainsi défini come une variation négative de ce portefeuille $L=-PnL$. La VaR au seuil de confiance $\\alpha$ est définie par :\n\n$$\nP(L\\leq VaR(\\alpha))=\\alpha\n$$\n\nRappelons que la VaR est égale au quantile d'ordre $\\alpha$ de $L$ . Ainsi, nous avons :\n\n$$\nVaR(\\alpha)=F^{-1}_L(\\alpha)\n$$\n\noù $F_L$ est la distribution associé à la variable aléatoire de perte $L$. Si nous considérons une écriture avec le PnL, nous avons $P(PnL\\geq - VaR(\\alpha))=\\alpha$ et nous déduisons que :\n\n$$\nVaR(\\alpha)=-F^{-1}_{PnL}(1-\\alpha)\n$$\n\nDans l'esprit des autorités réglementaires, la VaR vise à donner une image du risque de marché dans le cadre des conditions normales de marché. C'est pourquoi le seuil de confiance pour le risque de marché est généralement fixé à 99%, alors que celui des risques de crédit ou risques opérationnels est souvent plus élevé, à 99,9%. La période de détention est fixée à 10 jours de trading, ce qui reflète le temps que les autorités bancaires jugent nécessaire pour que la banque puisse retourner sa position en cas de besoin.\n\nPar ailleurs, les fonds propres calculés au titre du risque de marché ne sont pas destinés à faire face à des risques extrêmes. C'est pourquoi, en plus de calculer la VaR, les banques doivent la compléter par des scénarios de crise (stress-testing) qui permettent de mieux appréhender ces types de risque. Néanmoins, les résultats des stress-tests ne donnent pas lieu à une immobilisation de fonds propres réglementaires.\n\n# Calcul de la VaR\n\nPour calculer la VaR, il faut identifier les $m$ facteurs de marché $F_1, \\dots, F_m$ qui affectent les valeur future du portefeuille. En pratique, nous pouvons les déterminer en décomposant les instruments du portefeuille. Le calcul de la VaR dépendra alors de la méthodologie utilisée pour estimer la distribution de probabilité du PnL. D'une manière générale, nous avons le choix entre trois grandes familles de méthodes correpondant à trois approches différentes pour construire $\\hat F_{PnL}$ :\n\n1.  la VaR analytique ou paramétrique ou gaussienne\n\n2.  la VaR historique ou non paramétrique\n\n3.  la VaR monte-carlo\n\nLe comité de Bâle impose une période détention de dix jours pour calculer les fonds propres et une période de détention d'un jour pour l'exercice de backtesting. Ainsi, tous les jours, l'établissemnt financier doit calculer la VaR sur un jour et les fonds propres associés. Néanmoins, les autorités de supervision autorisent les banques à convertir la VaR sur un jour en VaR sur d'autres périodes de détention en utilisant la règle de la racine carrée ou scaling. Par exemple, pour obtenir la VaR sur 10 jours, il suffit de multiplier la VaR sur un jour par $\\sqrt{10}$.\n\n## Le backtesting\n\nLe backtesting est un contrôle de la qualité de la VaR pour un horizon de 1 jour. Il permet de vérifier si la VaR est bien calibrée. Pour cela, on compare la VaR calculée avec la perte réelle. Si la VaR est bien calibrée, la perte réelle ne doit pas dépasser la VaR dans 99,99% des cas. La commission bancaire utilise un nombre d'exception pour valider le modèle. Notons PnL le profit and loss du portefeuille et VaR la valeur à risque. Nous avons : \n$$\nP(PnL<-VaR)=1-\\alpha\n$$\n\nConsidérons maintenant la variable de bernoulli $I$ qui vaut 1 si le PnL est inférieur à l'opposé de la VaR avec probabilité $1-\\alpha$ (une exception) et 0 sinon. Pour une période ouvré comptant n jours, la probabilité d'avoir $i$ exceptions est donnée par la loi binomiale $\\mathcal{text{Bin}}(n,1-\\alpha)$. La probabilité d'avoir plus de $k$ exceptions est donnée par la loi binomiale cumulative $\\mathcal{B}(n,1-\\alpha)$. La probabilité d'avoir au plus de $i$ exceptions est donnée par : \n$$\nP(N_{ex}\\leq i)=\\sum_{j=0}^{i} \\binom{n}{j}(1-\\alpha)^j \\alpha^{n-j}\n$$\n\nPour tester que la probabilité d'exception n'excède pas $1-\\alpha$, nous pouvons utiliser un test de proportion. Si la proportion d'exceptions empirique est supérieur à celui attendu, le modèle est rejeté :\n\n$$\nH_0: P(PnL<-VaR)=1-\\alpha=p_0 \\quad \\text{vs} \\quad H_1: P(PnL<-VaR)>1-\\alpha=p_0\n$$\n\nLa statistique de test est donnée par (sous $H_0$) :\n$$\nT= \\frac{1}{n} \\sum_{i=1}^{n} I_{Pnl<-VaR} \\sim \\mathcal{N}(p_0,\\frac{p_0(1-p_0)}{n})\n$$\nqui donne la proportion d'exceptions observée lorsque $np>5$ et $n(1-p)>5$. \n\nLa p-valeur est donnée par $P(T>t|H_0)=1-\\phi(t)$ où $t$ est la valeur observée de la statistique de test et $\\phi$ est la fonction de répartition de la loi normale.\n# La VaR analytique\n\n## Cas général\n\nDans cette approche, nous considérons que les facteurs de risque sont gaussiens $PnL \\sim N(\\mu_{PnL}, \\sigma_{PnL})$ . Nous avons donc :\n\n\n\n```{=tex}\n\\begin{align*}\nP(PnL \\leq VaR) = 1 - \\alpha\\Leftrightarrow\\Phi \\left( \\frac{VaR - \\mu_{PnL}}{\\sigma_{PnL}} \\right) = 1 - \\alpha\n\\end{align*}\n```\n\n\nNous en déduisons donc que la VaR est calculé comme suit :\n\n$$\nVaR = -\\mu_{PnL} + \\Phi^{-1}(\\alpha) \\times \\sigma_{PnL}\n$$\n\nLorsque $\\alpha=99\\%$, $\\Phi^{-1}(\\alpha) = 2.33$. Remarquons que la VaR est une fonction décroissante de l'espérance de PnL et une fonction croissante de la volatilité du PnL. En pratique, nous posons $\\mu_{PnL}=0$ car il est difficle de prévoir l'espérance du PnL futur.\n\n### Exemple\n\nNous considérons une position courte de 1 million de dollars sur le contrat à terme S&P 500. Nous estimons que la volatilité annualisée $\\sigma_{\\text{SPX}}$ est égale à 35%.\n\nLa perte du portefeuille est égale à $L(w) = N \\times R_{\\text{SPX}}$ où $N$ est le montant de l'exposition (−1 million de dollars) et $R_{\\text{SPX}}$ est le rendement (gaussien) de l'indice S&P 500. Nous déduisons que la volatilité de la perte annualisée est $\\sigma(L) = |N| \\times \\sigma_{\\text{SPX}}$. La valeur à risque pour une période de détention d'un an est :\n\n$$\nVaR_{1Y}(99\\%)=2.33 \\times 0.35 \\times 1 000 000 = 815 500 \\text{ euros}\n$$\n\nAinsi, la perte maximale pour l'investisseur sur un 1an s'élève à 815 500€ avec un seuil de confiance de 99% (donc 1% de chance de se tromper).\n\nPour utiliser une autre période de détention, nous utilisons la règle de la racine carré pour convertir la volatilité pour une fréquence donné $f_1$ en une autre volatilité pour une autre fréquence $f_2$ : $\\sigma_{f_2}=\\sqrt{f_2/f_1}\\sigma_{f_1}$\n\nAinsi, nous obtenons pour les VaRs 1 mois et 1 jour les résultats suivants :\n\n\n\n```{=tex}\n\\begin{align*}\nVaR_{1M}(99\\%) &= \\frac{815 500}{\\sqrt{12}}=235414  \\text{ euros} \\\\\nVaR_{1J}(99\\%) &= \\frac{815 500}{\\sqrt{260}}=235414  \\text{ euros}\n\\end{align*}\n```\n\n\nEn pratique, la VaR est calculé sur 1 jour, pour l'avoir sur n jours, il faut donc appliquer cette formule :\n\n$$\nVaR_{nJ} =  VaR_(1J) \\times \\sqrt{n}\n$$\n\n## Modèles linéaires de facteurs\n\nNous considérons un portefeuille de $n$ actifs et une fonction de tarification $g$ qui est linéaire par rapport aux prix des actifs. Nous avons : $$\nP(t; \\theta) = \\sum_{i=1}^n \\theta_i P_{i}(t)\n$$\n\nIci, $P_i(t)$ est connu tandis que $P_i(t+h)$ est stochastique. La première idée est de choisir les facteurs comme étant les prix futurs.Dans cette approche, les rendements des actifs sont les facteurs de risque du marché et chaque actif possède son propre facteur de risque.\n\nLe problème est que les prix sont loin d'être stationnaires, ce qui nous amène à devoir affronter certains problèmes pour modéliser la distribution $F_t$. Une autre idée est de récrire le prix futur comme suit : $$\nP_i(t+h) = P_i(t) (1 + R_i(t;h))\n$$ où $R_i(t;h)$ est le retour de l'actif entre $t$ et $t+h$.\n\nNous déduisons que le PnL aléatoire est :\n\n\n\n```{=tex}\n\\begin{align*}\nPnL &= P(t+h,\\theta) - P(t,\\theta) \\\\\n&= \\sum_{i=1}^n \\theta_i P_i(t+h) - \\sum_{i=1}^n \\theta_i P_i(t) \\\\\n&= \\sum_{i=1}^n\\theta_i P_i(t) (1 - R_i(t,h))  - \\sum_{i=1}^n \\theta_i P_i(t) \\\\\n&= \\sum_{i=1}^n \\theta_i P_i(t)  R_i(t,h) \\\\\n&= \\sum_{i=1}^n W_i(t)  R_i(t,h)\n\\end{align*}\n```\n\n\noù $W_i = \\theta_i P_i(t)$ est le montant investi (ou l'exposition nominale)dans l'actif $i$.\n\n\\textbf{Le modèle de covariance}\n\nSoit $R(t,h)$ le vecteur des retours des actifs et $W_t = (W_{1,t}, \\dots, W_{n,t})$ le vecteur des montants investis. Il s'ensuit que : $$\nPnL = \\sum_{i=1}^n W_i(t) R_i(t) = W_t^T R(t,h)\n$$\n\nSi nous supposons que $R(t+h) \\sim N(\\mu, \\Sigma)$, nous déduisons que $\\mu(PnL) = W_t^T \\mu$ et $\\sigma^2(\\Pi) = W_t^T \\Sigma W_t$. Utilisant l'Équation (2.6), l'expression de la valeur à risque est : $$\n\\text{VaR}_\\alpha (w; h) = -W_t^T \\mu + \\phi^{-1}(\\alpha) \\sqrt{W_t^T \\Sigma W_t}\n$$\n\nDans cette approche, nous avons seulement besoin d'estimer la matrice de covariance des retours des actifs pour calculer la valeur à risque. Cela explique la popularité de ce modèle, surtout lorsque le P&L du portefeuille est une fonction linéaire des retours des actifs.\n\n### Exemple Apple & Coca-Cola\n\nConsidérons l'exemple des entreprises d'Apple et de Coca-Cola. Les expositions nominales sont de 1 093,3\\$ pour Apple et de 842,8\\$ pour Coca-Cola. Si nous prenons en compte les prix historiques du 7 janvier 2014 au 2 janvier 2015, l'écart type estimé des rendements quotidiens est de 1,3611 % pour Apple et de 0,9468 % pour Coca-Cola, tandis que la corrélation croisée est égale à 12,0787 %. Il s'ensuit que :\n\n\n\n```{=tex}\n\\begin{align*}\n\\sigma^2(PnL) &= W_t^T \\Sigma W_t = 1093.3^2 \\left(\\frac{1.3611}{100}\\right)^2 + 842.8^2 \\left(\\frac{0.9468}{100}\\right)^2 \\\\\n&+ 2 \\times 12.0787 \\times \\frac{1.0933 \\times 842.8 \\times 1.3611 \\times 0.9468}{10000} = 313.80\n\\end{align*}\n```\n\n\nSi nous omettons le terme de rendement attendu $-W_t^T \\mu$, nous déduisons que la valeur à risque quotidienne à 99% est de 41,21 \\$. Nous obtenons une figure inférieure à celle de la valeur à risque historique, qui était de 47,39 \\$. Nous expliquons ce résultat par le fait que la distribution gaussienne sous-estime la probabilité des événements extrêmes et n'est donc pas adaptée à des calculs précis de risque dans des situations de marché volatiles.\n\n### Exemple de portefeuille linéaire d'actifs\n\nConsidérons un portefeuille linéaire composé de trois actifs A (2 titres positions longues donc $\\theta_A=2$), B(1 titre position courte donc $\\theta_B=-1$) et C(1 titre position longue donc $\\theta_C=1$) dont les rendements journaliers sont en moyenne égaux à : $$\n\\mu = \n\\begin{pmatrix}\n50pb\\\\\n30pb \\\\\n20pb \n\\end{pmatrix} \n= \\begin{pmatrix}\n0.005\\\\\n0.003 \\\\\n0.002 \n\\end{pmatrix}\n$$\n\nLes volatilités journalières sont égales à 2%, 3% et 1%. Quant aux prix des actifs, ils sont respectivement de 244€, 135€,315€. La matrice de corrélation est donnée par : $$\n\\mu = \n\\begin{pmatrix}\n1 &\\\\\n0.5 & 1 & \\\\\n0.25 & 0.6 & 1 \n\\end{pmatrix} \n$$\n\nNous obtenons que:\n\n$$\nVaR(99\\%)=2.3263 \\times \\sqrt{82.1176} - 2.665 = 18.42\n$$\n\nLa perte maximale de ce portefeuille en une journée est donc de 18.42€ avec un risque 1% de se tromper.\n\n#### Implémentation en R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalculate_VaR <- function(mu,W_t,std_devs,correlation_matrix, alpha) {\n  # Dimensions de la matrice\n  n <- nrow(correlation_matrix)\n  \n  # Convertir les écarts-types et les corrélations en matrice de covariance\n  cov_matrix <- matrix(0, nrow = n, ncol = n)\n  for (i in 1:n) {\n    for (j in 1:n) {\n      cov_matrix[i, j] <- std_devs[i] * std_devs[j] * correlation_matrix[i, j]\n    }\n  }\n  \n  q<-qnorm(alpha, mean = 0, sd = 1)\n\n  VaR<- -t(W_t) %*% mu + 2.3263*sqrt(t(W_t) %*% cov_matrix %*% W_t)\n\n  return(VaR)\n}\n\n\nW_t <- matrix(c(2*244, -1*135, 1*315),nrow = 3)\nmu <- matrix(c(50,30,20),nrow = 3)/10000\nstd_devs<- c(2,3,1)/100\n\n# Matrice de corrélation\ncorrelation_matrix <- matrix(c(\n1,0.5,0.25,\n0.5,1,0.6,\n0.25,0.6,1\n), nrow = 3, byrow = TRUE)\n\nVaR<- calculate_VaR(mu,W_t,std_devs,correlation_matrix,0.99)\nVaR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 18.41564\n```\n\n\n:::\n:::\n\n\n\n## Modèles factoriels de risque\n\nNous supposons que la valeur du portefeuille dépend de $m$ facteurs de risque. Nous avons que la valeur du portefeuille à $t+h$ dépend des facteurs de risques :\n\n$$\nP(t+h,\\theta) = g(F_1(t+h), \\dots, F_m(t+h);\\theta)\n$$\n\noù g est la fonction de valorisation (pricing function)\n\nSupposons maintenant que le portefeuille soit linéaire par rapport aux facteurs de risque, ainsi donc le retour des actifs à l'horizon h est :\n\n\\begin{align*}\nR(t,h)&= B F(t,h) + \\epsilon(t,h) \\\\\n\\end{align*} où $B$ est la matrice des sensibilités du portefeuille aux facteurs de risque (interne, commun) et $F(t,h)$ est le vecteur des facteurs de risque à l'horizon h avec $E(F)=\\mu(F)$ et $cov(F)=\\Omega$. De plus, $\\epsilon(t,h)$ est le vecteur des erreurs qui sont des variables aléatoires gaussiennes indépendantes avec $E(\\epsilon)=0$ et $cov(\\epsilon)=D$.\n\nSi le retour des actifs est gaussien, nous en deduisons que le PnL est une variable aléatoire gaussienne:\n\n$$\nPnL \\sim \\mathcal{N}(W_t^TB^T\\mu(F), W_t^T (B\\Omega B^T + D) W_t)\n$$\n\nAinsi donc la VaR est calculé comme suit : $VaR=-W_t^TB^T\\mu(F) + \\Phi^{-1}(\\alpha)\\sqrt{ W_t^T (B\\Omega B^T + D) W_t)}$\n\nCette méthode repose sur 3 hypothèses : l'indépendance temporelle des variations de la valeur du portefeuille, la normalité des facteurs et la relation linéaire entre les facteurs et la valeur du portefeuille. En général, nous ne connaissons pas $B, \\mu, \\Sigma$. Dans la pratique, nous les estimons à partir des données historiques des facteurs et $B$ est le vecteur des sensibilités du portefeuille aux facteurs de risque. La seuil difficulté de cette méthode est l'estimation de la matrice de variance covariance.\n\n### Exemple d'un portefeuille obligataire sans risque de crédit\n\nNous considérons une exposition sur une obligation américaine à \\$t=\\$31 décembre 2014. Le nominal de l'obligation est de 100 tandis que les coupons annuels $C(t_m)$ sont égaux à 5, $t_m>t$. La maturité résiduelle est de cinq ans et les dates de fixation sont à la fin de décembre ($n_C=5$. Le nombre d'obligations détenues dans le portefeuille est de 10 000.\n\nNous notons $B_t(T)$ le prix d'une obligation zéro coupon (montant qu'un investisseur serait prêt à payer aujourd'hui pour recevoir un paiement fixe à une date future : combien me rapport un euro à maturité $T$ aujourd'hui?) au temps $t$ pour l'échéance $T$. Nous avons $B_t(T) = e^{-(T - t)R_t(T)}$ où $R_t(T)$ est le taux de rendement zéro coupon.\n\nLa valeur de l'obligation est donc : $$\nP(t) =  \\sum_{m=1}^{n_C} C(t_m) B_t(t_m)\n$$\n\nOn en déduit que le PnL est : \\begin{align*}\nPnL &=  ( \\sum_{m=1}^{n_C} C(t_m) B_{t+h}(t_m) - \\times \\sum_{m=1}^{n_C} C(t_m) B_t(t_m) )\\\\\n&=  -\\sum_{m=1}^{n_C} C(t_m) (t_m - t) B_{t}(t_m) \\Delta R(t+h,t_m)) \\\\\n&=  \\sum_{m=1}^{n_C} W_t(tm) \\Delta R(t+h,t_m) \\\\\n\\end{align*}\n\noù $W_t(t_m) = -C(t_m)(t_m-t) B_t(t_m)$ est le montant investi dans l'obligation $m$ et $\\Delta R(t+h,t_m)$ est le rendement de l'obligation $m$ entre $t$ et $t+h$.\n\n| $t_m - t$ | $C(t_m)$ | $R_t(t_m)$ | $B_t(t_m)$ | $W_{t_m}$ |\n|-----------|----------|------------|------------|-----------|\n| 1         | 5        | 0.431%     | 0.996      | -4.978    |\n| 2         | 5        | 0.879%     | 0.983      | -9.826    |\n| 3         | 5        | 1.276%     | 0.962      | -14.437   |\n| 4         | 5        | 1.569%     | 0.939      | -18.783   |\n| 5         | 105      | 1.777%     | 0.915      | -480.356  |\n\nNous en déduisons que le prix de l'obligation est de $P(t)=115,47 \\$$ et l'exposition totale est de 1 154 706 \\$. En utilisant la période historique de l'année 2014, nous estimons la matrice de covariance entre les variations quotidiennes des cinq taux d'intérêt à coupon zéro sachant que l'écart-type est respectivement de 0,746 pb pour $\\Delta_h R_t(t + 1)$, 2,170 pb pour $\\Delta_h R_t(t + 2)$, 3,264 pb pour $\\Delta_h R_t(t + 3)$, 3,901 pb pour $\\Delta_h R_t(t + 4)$ et 4,155 pb pour $\\Delta_h R_t(t + 5)$, où $h$ correspond à un jour de bourse. Pour la matrice de corrélation en pb (points de base), nous obtenons :\n\n$$\n\\rho = \n\\begin{pmatrix}\n100.000 &  \\\\\n87.205 & 100.000 \\\\\n79.809 & 97.845 & 100.000 \\\\\n75.584 & 95.270 & 98.895 & 100.000  \\\\\n71.944 & 92.110 & 96.556 & 99.219 & 100.000 \\\\\n\\end{pmatrix}\n$$\n\nNous en déduisons que la valeur à risque à 99% est (en supposant que la moyenne du PnL est nulle): $$\nVaR= 2.33 * \\sqrt{W_t^T \\Sigma W_t}\n$$ Nous obtenons une valeur à risque de 4970\\$ pour une période de détention d'un jour.\n\n#### Implémentation en R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Définition des écarts-types en points de base convertis en pourcentage\nstd_devs <- c(0.746, 2.170, 3.264, 3.901, 4.155)/10000\n\n# Matrice de corrélation\ncorrelation_matrix <- matrix(c(\n  100, 87.205, 79.809, 75.584, 71.944,\n  87.205, 100, 97.845, 95.270, 92.110,\n  79.809, 97.845, 100, 98.895, 96.556,\n  75.584, 95.270, 98.895, 100, 99.219,\n  71.944, 92.110, 96.556, 99.219, 100\n), nrow = 5, byrow = TRUE)/100\n\nW_tm <- matrix(c(-4.978, -9.826, -14.437, -18.783, -480.356),nrow = 5)*10000\nmu<-rep(0,5)\n\nVaR<-calculate_VaR(mu,W_tm,std_devs,correlation_matrix,0.99)\nVaR\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         [,1]\n[1,] 4970.384\n```\n\n\n:::\n:::\n\n\n\n# La VaR historique\n\nDans cette approche, nous ne faisons pas d'hypothèse sur la distribution des facteurs. A l'instant t, le portefeuille est valorisé en appliquant les facteurs de risque mesurés historiquement. Soit $F_1^{i}, \\dots, F_m^{i}$ les valeurs des facteurs de risque du $i$-ème scénario historique. La valeur du profit & loss (PnL) du portefeuille du $i$-eme scénario est donc : $$\nPnL_i = P(t+h,\\theta) - P(t,\\theta) = g(F_1^{i}, \\dots, F_m^{i};\\theta) - P(t,\\theta)\n$$\n\nConsidérant les $n$ scénarios, la probabilité d'occurence est la même pour chaque scénario, nous avons donc $1/N$ pour chaque scénario. La VaR est donc le quantile empirique de l'échantillon des PnL. Pour le calculer au seuil de confiance $\\alpha$, nous ordonnons les PnL de manière croissante (les statistiques d'ordre): $$\nmin(PnL_i)=PnL_{1:n} \\leq PnL_{2:n} \\leq \\dots \\leq PnL_{n:n}=max(PnL_i)\n$$\n\nPar la suite, nous estimons la VaR en prenant l'opposé de la $n \\times (1-\\alpha)$-ème plus petite valeur de l'échantillon. La VaR est donc : $$\nVaR(\\alpha) = - PnL_{n \\times (1-\\alpha):n}\n$$\n\nLorsque $n \\times (1-\\alpha)$ n'est pas entier, il faut procéder par interpolation linéaire :\n\n\n\n```{=tex}\n\\begin{align*}\nVaR(\\alpha) &= - PnL_{\\lfloor n \\times (1-\\alpha) \\rfloor:n} + (n \\times (1-\\alpha) - \\lfloor n \\times (1-\\alpha) \\rfloor) \\times (PnL_{\\lfloor n \\times (1-\\alpha) \\rfloor+1:n} - PnL_{\\lfloor n \\times (1-\\alpha) \\rfloor:n})\n\\end{align*}\n```\n\n\noù $\\lfloor x \\rfloor$ est la partie entière de $x$. Par exemple, pour un échantillon de taille 1000, la VaR à 99% est la 10ème plus petite valeur de l'échantillon.\n\n# La VaR Monte-Carlo\n\nLa VaR Monte-Carlo est une méthode de simulation qui consiste à simuler les facteurs de risque et à calculer le PnL pour chaque scénario. La VaR est ensuite estimée en prenant le quantile empirique de l'échantillon des PnL. La méthode est plus flexible que la VaR historique car elle permet de simuler des scénarios qui n'ont pas été observés dans le passé et la taille d'échantillon n'est pas contrainte. Cependant, elle est plus coûteuse en temps de calcul.\n\nPour la $s$-ieme simulation, nous avons donc : $$\nPnL_s = P(t+h,\\theta) - P(t,\\theta) = g(F_1^{s}, \\dots, F_m^{s};\\theta) - P(t,\\theta)\n$$\n\nIl suffit ensuite de calculer le quantile correspondant comme pour la méthode de la VaR historique. Lorsque l'on suppose que les facteurs de risque suivent une distribution gaussienne, nous avons asymptotiquement les mêmes résultats que la VaR analytique.\n\n# Explication d'un facteur complémentaire\n\nLes méthodes de valeur en risque ne donnent qu'une estimation de la perte potentielle au seuil de confiance $\\alpha$. Cependant, elle peut être différente de la perte potentielle réelle pour plusieurs raisons (hypothèses de normalité, estimation des paramètres, taille de l'échantillon, etc.). C'est pourquoi les autorités réglementaires demandent aux établissements financiers de corriger l'estimation de la VaR par un facteur complémentaire. Ce facteur est souvent appelé facteur de multiplication ou facteur de prudence $3 + \\xi$. Il est souvent compris entre 3 et 5.\n\nEtant donné la perte $L$ de distribution $F$. L'idée sous-jacente est de définir un coefficient $\\kappa$ tel que $P(L \\leq \\kappa \\times VaR) = \\alpha$. Par exemple, si la distribution $F$ de la perte est effectivement gaussienne, le coefficient $\\kappa$ est égal à 1. Si cette distribution présente des queues épaisses, on peut s'attendre à ce que ce coefficient soit plus grand .\n\nPour déterminer ce coefficient, nous utilisons l'égalité de Bienaymé-tchebycheff : $$\nP(|L - \\mu(L)| \\geq \\kappa \\times \\sigma_L) \\leq \\frac{1}{\\kappa^2}\n$$ où $\\mu(L)$ est l'espérance de la perte(supposé nul) et $\\sigma_L$ est l'écart-type de la perte.\n\nSi la distribution est asymétrique, nous en déduisons que :\n\n$$\nP(L \\leq \\kappa \\times \\sigma(L)) \\geq 1 - \\frac{1}{\\kappa^2}\n$$\n\nSupposons $\\alpha=1-\\frac{1}{\\kappa^2}$, nous obtenons : $$\nP(L \\leq \\sqrt{\\frac{1}{1-\\alpha}} \\times \\sigma(L)) \\geq \\alpha\n$$\n\nComme $VaR_{\\text{gaussienne}}=\\Phi^{-1}(\\alpha) \\times \\sigma(L)$ (puisque $\\mu(L)=0$), nous en déduisons que\n\n\n\n```{=tex}\n\\begin{align*}\n\\kappa &= \\frac{\\sqrt{\\frac{1}{1-\\alpha}} \\times \\sigma(L)}{VaR_{\\text{gaussienne}}} \\\\\n&= \\frac{1}{\\Phi^{-1}(\\alpha)}\\times \\sqrt{\\frac{1}{1-\\alpha}}\n\\end{align*}\n```\n\n\n|           |                     | Symétrique | Symétrique | Asymétrique | Asymétrique |\n|------------|------------|------------|------------|------------|------------|\n| $\\alpha$  | $\\Phi^{-1}(\\alpha)$ | $k$        | $\\kappa$   | $k$         | $\\kappa$    |\n| 90.00     | 1.28                | 2.24       | 1.74       | 3.16        | 2.47        |\n| 95.00     | 1.64                | 3.16       | 1.92       | 4.47        | 2.72        |\n| **99.00** | **2.33**            | **7.07**   | **3.04**   | **10.00**   | **4.30**    |\n| 99.25     | 2.43                | 8.16       | 3.36       | 11.55       | 4.75        |\n| **99.50** | **2.58**            | **10.00**  | **3.88**   | **14.14**   | **5.49**    |\n| 99.75     | 2.81                | 14.14      | 5.04       | 20.00       | 7.12        |\n| 99.99     | 3.72                | 70.71      | 19.01      | 100.00      | 26.89       |\n\n: Valeur numérique de $\\kappa$ pour différents seuils de confiance\n\nPour mesurer l'asumétrie de la distribution, nous utilisons les moments d'ordre supérieur à 2 : le skewness et le kurtosis. Le skewness est une mesure de l'asymétrie de la distribution et le kurtosis est une mesure de la concentration des valeurs autour de la moyenne. Soit le moment centré d'ordre $r$ par $\\mu_r=E[(X-\\mu)^r]$. Le skewness est défini comme suit :\n\n$$\n\\gamma_1=\\frac{\\mu_3}{\\sigma^3}\n$$ Si le skewness est nul, la distribution est symétrique (par exemple, la loi normale). La distribution est asymétrique à droite (resp. à gauche) si $\\gamma_1 < 0$ (resp. $\\gamma_1 > 0$)\n\nLe kurtosis se définit comme suit : $$\n\\nu_4=\\frac{\\mu_4}{\\sigma^4} \n$$\n\nSi le kurtosis est égal à 3, la distribution est dite normale. Si le kurtosis est supérieur à 3, la distribution est dite leptokurtique (queues épaisses), c'est le cas de la distribution de student et si le kurtosis est inférieur à 3, la distribution est dite platykurtique (queues fines).\n\nEn pratique, on considère plutôt $\\gamma_2=\\nu_4-3$ qui est appelé l'excès de kurtosis. La VaR analytique ne prend pas en compte ces effets. Néanmoins, nous pouvons les intégrer comme suit :\n\n$$\nVaR(\\alpha) = z_{\\alpha}(\\gamma_1,\\gamma_2) \\times \\sigma\n$$\n\navec $z_{\\alpha}(\\gamma_1,\\gamma_2) = z_{\\alpha} + \\frac{1}{6}(z_{\\alpha}^2 -1)\\gamma_1+ \\frac{1}{24}(z_{\\alpha}^3-3z_{\\alpha})\\gamma_2) -  \\frac{1}{36}(2z_{\\alpha}^3 -5z_{\\alpha})\\gamma_1^2+\\dots$ et $z_{\\alpha}=\\Phi^{-1}(\\alpha)$. Cette formule est l'expansion de corner-fisher.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}